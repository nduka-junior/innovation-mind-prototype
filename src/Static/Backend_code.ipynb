{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "import pinecone\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "pinecone.init(api_key=\"your pinecone api key\", environment=\"your environment\")\n",
        "\n",
        "pinecone_index_name = \"semantic-search-openai\"\n",
        "\n",
        "if pinecone_index_name in pinecone.list_indexes():\n",
        "    print(f\"Index {pinecone_index_name} already exists. Skipping creation.\")\n",
        "else:\n",
        "    # Load the dataset into a Pandas DataFrame\n",
        "    df = pd.read_csv(\"wiki.csv\")\n",
        "\n",
        "    # Create an empty Pinecone index with the desired dimension\n",
        "    pinecone.create_index(name=pinecone_index_name, dimension=329)\n",
        "\n",
        "    # Populate the index with vectors for each row in the dataset\n",
        "    for i, row in df.iterrows():\n",
        "        text_data = row['text']\n",
        "        vector = cohere_embed.embed(text_data)\n",
        "        pinecone.upsert(pinecone_index_name, [vector], [i])\n",
        "\n",
        "    print(f\"Index {pinecone_index_name} created and populated successfully.\")\n",
        "\n",
        "#pinecone.deinit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJCIqXI9dRDX",
        "outputId": "01c71410-737e-48de-bf5c-0abd306c32ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index semantic-search-openai already exists. Skipping creation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install cohere\n",
        "#!pip install --upgrade pinecone-client\n",
        "#!pip install openai\n",
        "\n",
        "#!pip install cohere_embed_api\n",
        "import pinecone\n",
        "import openai\n",
        "import cohere\n",
        "import pandas as pd\n",
        "#import cohere_embed_api as co\n",
        "\n",
        "# Initialize Pinecone and OpenAI\n",
        "#pinecone.init(api_key=\"pinecone api key\")\n",
        "openai.api_key = \"openai api key\"\n",
        "\n",
        "# Load the \"wiki.csv\" dataset into a Pandas DataFrame\n",
        "df = pd.read_csv(\"wiki.csv\")\n",
        "\n",
        "# Define the name of the Pinecone index that contains the text data vectors\n",
        "pinecone_index_name = \"wiki_index\"\n",
        "\n",
        "# Define the maximum number of results to return from Pinecone and OpenAI\n",
        "max_results = 5\n",
        "\n",
        "# Prompt the user for input\n",
        "user_input = str(input(\"Enter a question: \"))\n",
        "\n",
        "# Use the Cohere Embed API to detect the language of the input\n",
        "co = cohere.Client('cohere api key')\n",
        "language = co.detect_language(texts=[user_input])\n",
        "\n",
        "# Use the Pinecone API to search for the most similar vectors in the index\n",
        "if language == \"unknown\":\n",
        "    print(\"Language detection failed. Please try again with a different question.\")\n",
        "else:\n",
        "    #embedding = cohere_client.embed(texts=[\"Hello World\",\"2023 will be my year\"])\n",
        "    vector = co.embed(texts=[user_input])\n",
        "    print(vector)\n",
        "    #search_results = pinecone.query(index_name=pinecone_index_name, queries=[vector], top_k=10)\n",
        "\n",
        "    # Use the OpenAI Completion API to generate a response for the input\n",
        "    completions = openai.Completion.create(\n",
        "        engine=\"davinci\",\n",
        "        prompt=user_input,\n",
        "        max_tokens=512,\n",
        "        n=5,\n",
        "        stop=None,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    response = completions.choices[0].text.strip()\n",
        "\n",
        "    # Print the search results and the response\n",
        "    print(f\"Top {max_results} search results:\")\n",
        "    #for i, (idx, score) in enumerate(search_results[0]):\n",
        "        #text_data = df.loc[int(idx)]['text']\n",
        "        #print(f\"{i+1}. {text_data} (score: {score:.3f})\")\n",
        "    print(f\"\\nResponse: {response}\")\n",
        "    print(type(response))\n",
        "    \n",
        "# Deinitialize Pinecone\n",
        "#pinecone.deinit()"
      ],
      "metadata": {
        "id": "JhrMHE9tiqFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "#print(response)\n",
        "# Extract the generated text from OpenAI response\n",
        "generated_text = response\n",
        "\n",
        "# Define the Pinecone index name\n",
        "#pinecone_index_name = \"my-index\"\n",
        "pinecone.init(api_key=\"pinecone api key\", environment=\"your environment\")\n",
        "\n",
        "pinecone_index_name = \"semantic-search-openai\"\n",
        "# Insert the generated text into the Pinecone index\n",
        "pinecone.upsert(index_name=pinecone_index_name, ids=[\"id-1\"], vectors=[generated_text])\n",
        "\n",
        "# Define the Pinecone query vector\n",
        "query_vector = generated_text\n",
        "\n",
        "# Perform a Pinecone search on the index and retrieve the top result\n",
        "search_results = pinecone.query(index_name=pinecone_index_name, queries=[query_vector], top_k=1)\n",
        "top_result_id = search_results[0][\"id\"]\n",
        "\n",
        "# Retrieve the summary from Pinecone using the top result ID\n",
        "summary = pinecone.retrieve(index_name=pinecone_index_name, ids=[top_result_id])[0][\"vectors\"][0]\n",
        "\n",
        "print(\"Generated text:\", generated_text)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "id": "7aWW2CC8fP_s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}